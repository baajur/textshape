---
title: "textshape"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  md_document:
    toc: true      
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(knitr)
desc <- suppressWarnings(readLines("DESCRIPTION"))
regex <- "(^Version:\\s+)(\\d+\\.\\d+\\.\\d+)"
loc <- grep(regex, desc)
ver <- gsub(regex, "\\2", desc[loc])
verbadge <- sprintf('<a href="https://img.shields.io/badge/Version-%s-orange.svg"><img src="https://img.shields.io/badge/Version-%s-orange.svg" alt="Version"/></a></p>', ver, ver)
```


```{r, echo=FALSE}
knit_hooks$set(htmlcap = function(before, options, envir) {
  if(!before) {
    paste('<p class="caption"><b><em>',options$htmlcap,"</em></b></p>",sep="")
    }
    })
knitr::opts_knit$set(self.contained = TRUE, cache = FALSE)
knitr::opts_chunk$set(fig.path = "inst/figure/")
```

[![Project Status: Active - The project has reached a stable, usable state and is being actively developed.](http://www.repostatus.org/badges/0.1.0/active.svg)](http://www.repostatus.org/#active)
[![Build Status](https://travis-ci.org/trinker/textshape.svg?branch=master)](https://travis-ci.org/trinker/textshape)
[![Coverage Status](https://coveralls.io/repos/trinker/textshape/badge.svg?branch=master)](https://coveralls.io/r/trinker/textshape?branch=master)
`r verbadge`

<img src="inst/textshape_logo/r_textshape.png" width="200" alt="textshape Logo">  

**textshape** is small suite of text reshaping functions.  Many of these functions are descended from tools in the [**qdapTools**](https://github.com/trinker/qdapTools) package.  This brings reshaping tools under one roof with specific functionality of the package limited to text reshaping.

# Functions

Most of the functions split/expand a `vector`, `list`, `data.frame`, or `DocumentTermMatrix`.  The `combine`, `bind_list`, `duration`, & `mtabulate` functions are notable exceptions.  The table below describes the functions and their use:

| Function         | Used On                        |  Description                                                 |
|------------------|--------------------------------|--------------------------------------------------------------|
| `combine`        | `vector`, `list`, `data.frame` | Combine and collapse elements                                |
| `bind_list`      | `list` of `vector`s or `data.frame`s | Row bind a list and repeat list names as id column     |
| `bind_vector`    | `vector`                       | Column bind a named atomic `vector`'s names and values       |
| `bind_table`     | `table`                        | Column bind a `table`'s names and values                     |
| `duration`       | `vector`, `data.frame`         | Get duration (start-end times) for turns of talk in n words  |
| `from_to`        | `vector`, `data.frame`         | Prepare speaker data for a flow network                      |
| `mtabulate`      | `vector`, `list`, `data.frame` | Dataframe/list version of `tabulate` to produce count matrix |
| `split_index`    | `vector`, `list`, `data.frame` | Split at specified indices                                   |
| `split_match`    | `vector`                       | Split vector at specified character/regex match              |
| `split_portion`  | `vector`\*                     | Split data into portioned chunks                             |
| `split_run`      | `vector`, `data.frame`         | Split runs (e.g., "aaabbbbcdddd")                            |
| `split_sentence` | `vector`, `data.frame`         | Split sentences                                              |
| `split_speaker`  | `data.frame`                   | Split combined speakers (e.g., "Josh, Jake, Jim")            |
| `split_token`    | `vector`, `data.frame`         | Split words and punctuation                                  |
| `split_transcript` | `vector`                     | Split speaker and dialogue (e.g., "greg: Who me")            |
| `split_word`     | `vector`, `data.frame`         | Split words                                                  |
| `tidy_dtm`/`tidy_tdm` | `DocumentTermMatrix`      | Tidy format `DocumentTermMatrix`/`TermDocumentMatrix`        |
| `tidy_colo_dtm`/`tidy_colo_tdm` | `DocumentTermMatrix`      | Tidy format collocating words  from a `DocumentTermMatrix`/`TermDocumentMatrix`        |

\****Note:*** *Text vector accompanied by aggregating `grouping.var` argument, which can be in the form of a `vector`, `list`, or  `data.frame`*



# Installation

To download the development version of **textshape**:

Download the [zip ball](https://github.com/trinker/textshape/zipball/master) or [tar ball](https://github.com/trinker/textshape/tarball/master), decompress and run `R CMD INSTALL` on it, or use the **pacman** package to install the development version:

```r
if (!require("pacman")) install.packages("pacman")
pacman::p_load_gh("trinker/textshape")
```

# Contact

You are welcome to:
* submit suggestions and bug-reports at: <https://github.com/trinker/textshape/issues>
* send a pull request on: <https://github.com/trinker/textshape/>
* compose a friendly e-mail to: <tyler.rinker@gmail.com>


# Examples

The main shaping functions can be broken into the categories of (a) binding, (b) combining, &#40;c) tabulating, (d) spanning, & (e) splitting.  The majority of functions in **textshape** fall into the last category of splitting and expanding (the semantic opposite of combining).  These sections will provide example uses of the functions from **textshape** within the three categories.

## Binding

The `bind_list` function is used in the style of `do.call(rbind, list(x1, x2))` as a convenient way to bind together multiple named `data.frame`s or `vectors`s into a single `data.frame` with the `list` `names` acting as an id column.  The `data.frame` bind is particularly useful for binding transcripts from different observations.  Additionally, `bind_vector` and `bind_table` ar provided for `cbinding` a `table`'s or named atomic `vector`'s values and names as separate columns in a `data.frame`.

#### A Vector

```{r}
x <- list(p=1:500, r=letters)
bind_list(x)
```

#### A Dataframe

```{r}
x <- list(p=mtcars, r=mtcars, z=mtcars, d=mtcars)
bind_list(x) 
```

#### A Named Vector

```{r}
x <- setNames(
    sample(LETTERS[1:6], 1000, TRUE), 
    sample(state.name[1:5], 1000, TRUE)
)
bind_vector(x)
```

#### A Table

```{r}
x <- table(sample(LETTERS[1:6], 1000, TRUE))
bind_table(x)
```

## Combining

The `combine` function acts like `paste(x, collapse=" ")` on vectors and lists of vectors.  On dataframes multiple text cells are pasted together within grouping variables.

#### A Vector

```{r}
x <- c("Computer", "is", "fun", ".", "Not", "too", "fun", ".")
combine(x)
```

#### A Dataframe

```{r}
(dat <- split_sentence(DATA))
combine(dat[, 1:5, with=FALSE])
```

## Tabulating

`mtabulate` allows the user to transform data types into a dataframe of counts.

#### A Vector

```{r}
(x <- list(w=letters[1:10], x=letters[1:5], z=letters))
mtabulate(x)

## Dummy coding
mtabulate(mtcars$cyl[1:10])
```


#### A Dataframe

```{r}
(dat <- data.frame(matrix(sample(c("A", "B"), 30, TRUE), ncol=3)))
mtabulate(dat)
t(mtabulate(dat))
```

## Spanning

Often it is useful to know the duration (start-end) of turns of talk.  The `duration` function calculations start-end durations as n words.


#### A Vector

```{r}
(x <- c(
    "Mr. Brown comes! He says hello. i give him coffee.",
    "I'll go at 5 p. m. eastern time.  Or somewhere in between!",
    "go there"
))
duration(x)
# With grouping variables
groups <- list(group1 = c("A", "B", "A"), group2 = c("red", "red", "green"))
duration(x, groups)
```


#### A Dataframe

```{r}
duration(DATA)
```

#### Gantt Plot

```{r}
library(ggplot2)
ggplot(duration(DATA), aes(x = start, xend = end, y = person, yend = person, color = sex)) +
    geom_segment(size=4) +
    xlab("Duration (Words)") +
    ylab("Person")
```

## Splitting

The following section provides examples of available splitting functions.

### Indices

`split_index` allows the user to supply the integer indices of where to split a data type.

#### A Vector

```{r}
split_index(LETTERS, c(4, 10, 16), c("dog", "cat", "chicken", "rabbit"))
```

#### A Dataframe

Here I calculate the indices of every time the `vs` variable in the `mtcars` data set changes and then split the dataframe on those indices.  The `change_index` function is handy for extracting the indices of changes in runs within an [atomic vector](http://arrgh.tim-smith.us/atomic.html).

```{r}
(vs_change <- change_index(mtcars[["vs"]]))
split_index(mtcars, vs_change)
```

### Matches

`split_match` splits on elements that match exactly or via a regular expression match.

#### Exact Match

```{r}
set.seed(15)
(x <- sample(c("", LETTERS[1:10]), 25, TRUE, prob=c(.2, rep(.08, 10))))

split_match(x)
split_match(x, "C")
split_match(x, c("", "C"))
## Don't include
split_match(x, include = 0)
## Include at beginning
split_match(x, include = 1)
## Include at end
split_match(x, include = 2)
```

#### Regex Match

Here I use the regex `"^I"` to break on any vectors containing the capital letter I as the first character.

```{r}
split_match(DATA[["state"]], "^I", regex=TRUE, include = 1)
```


### Portions

At times it is useful to split texts into portioned chunks, operate on the chunks and aggregate the results.  `split_portion` allows the user to do this sort of text shaping.  We can split into n chunks  per grouping variable (via `n.chunks`) or into chunks of n length (via `n.words`).

#### A Vector


```{r}
with(DATA, split_portion(state, n.chunks = 10))
with(DATA, split_portion(state, n.words = 10))
```

#### A Dataframe

```{r}
with(DATA, split_portion(state, list(sex, adult), n.words = 10))
```


### Runs

`split_run` allows the user to split up runs of identical characters.

```{r}
x1 <- c(
     "122333444455555666666",
     NA,
     "abbcccddddeeeeeffffff",
     "sddfg",
     "11112222333"
)

x <- c(rep(x1, 2), ">>???,,,,....::::;[[")

split_run(x)
```

#### Dataframe

```{r}
DATA[["run.col"]] <- x
split_run(DATA)
## Reset the DATA dataset
DATA <- textshape::DATA
```

### Sentences

`split_sentece` provides a mapping + regex approach to splitting sentences.  It is less accurate than the Stanford parser but more accurate than a simple regular expression approach alone.

#### A Vector

```{r}
(x <- paste0(
    "Mr. Brown comes! He says hello. i give him coffee.  i will ",
    "go at 5 p. m. eastern time.  Or somewhere in between!go there"
))
split_sentence(x)
```

#### A Dataframe

```{r}
split_sentence(DATA)
```

### Speakers

Often speakers may talk in unison.  This is often displayed in a single cell as a comma separated string of speakers.  Some analysis may require this information to be parsed out and replicated as one turn per speaker.  The `split_speaker` function accomplishes this.

```{r}
DATA$person <- as.character(DATA$person)
DATA$person[c(1, 4, 6)] <- c("greg, sally, & sam",
    "greg, sally", "sam and sally")
DATA

split_speaker(DATA)
## Reset the DATA dataset
DATA <- textshape::DATA
```

### Tokens

The `split_token` function split data into words and punctuation.

#### A Vector

```{r}
(x <- c(
    "Mr. Brown comes! He says hello. i give him coffee.",
    "I'll go at 5 p. m. eastern time.  Or somewhere in between!",
    "go there"
))
split_token(x)
```

#### A Dataframe

```{r}
 split_token(DATA)
```


### Transcript

The `split_transcript` function splits `vector`s with speaker prefixes (e.g., `c("greg: Who me", "sarah: yes you!")`) into a two column `data.frame`.

#### A Vector

```{r}
(x <- c(
    "greg: Who me", 
    "sarah: yes you!",
    "greg: well why didn't you say so?",
    "sarah: I did but you weren't listening.",
    "greg: oh :-/ I see...",
    "dan: Ok let's meet at 4:30 pm for drinks"
))

split_transcript(x)
```

### Words

The `split_word` function splits data into words.

#### A Vector

```{r}
(x <- c(
    "Mr. Brown comes! He says hello. i give him coffee.",
    "I'll go at 5 p. m. eastern time.  Or somewhere in between!",
    "go there"
))
split_word(x)
```

#### A Dataframe

```{r}
 split_word(DATA)
```


### Tidying DocumentTermMatrix

The `tidy_dtm` and `tidy_tdm` functions convert a `DocumentTermMatrix` or `TermDocumentMatrix` into a tidied data set.  

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_current_gh('trinker/gofastr')
pacman::p_load(tidyverse, magrittr, ggstance)

my_dtm <- with(presidential_debates_2012, q_dtm(dialogue, paste(time, tot, sep = "_")))

tidy_dtm(my_dtm) %>%
    tidyr::extract(doc, c("time", "turn", "sentence"), "(\\d)_(\\d+)\\.(\\d+)") %>%
    mutate(
        time = as.numeric(time),
        turn = as.numeric(turn),
        sentence = as.numeric(sentence)
    ) %>%
    tbl_df() %T>%
    print() %>%
    group_by(time, term) %>%
    summarize(n = sum(n)) %>%
    group_by(time) %>%
    arrange(desc(n)) %>%
    slice(1:10) %>%
    mutate(term = factor(paste(term, time, sep = "__"), levels = rev(paste(term, time, sep = "__")))) %>%
    ggplot(aes(x = n, y = term)) +
        geom_barh(stat='identity') +
        facet_wrap(~time, ncol=2, scales = 'free_y') +
        scale_y_discrete(labels = function(x) gsub("__.+$", "", x))
```


### Tidying DocumentTermMatrix of Collocations

The `tidy_colo_dtm` and `tidy_colo_tdm` functions convert a `DocumentTermMatrix` or `TermDocumentMatrix` into a collocation matrix and then a tidied data set.  

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load_current_gh('trinker/gofastr', 'trinker/lexicon')
pacman::p_load(tidyverse, magrittr, ggstance)

my_dtm <- with(presidential_debates_2012, q_dtm(dialogue, paste(time, tot, sep = "_")))

tidy_colo_dtm(my_dtm) %>%
    tbl_df() %>%
    filter(!term_1 %in% c('i', lexicon::sw_onix) & !term_2 %in% lexicon::sw_onix) %>%
    filter(term_1 != term_2) %>%
    unique_pairs() %>%
    filter(n > 15) %>%
    complete(term_1, term_2, fill = list(n = 0)) %>%
    ggplot(aes(x = term_1, y = term_2, fill = n)) +
        geom_tile() +
        scale_fill_gradient(low= 'white', high = 'red') +
        theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


## Putting It Together 

Eduardo Flores blogged about [What the candidates say, analyzing republican debates using R](https://www.r-bloggers.com/what-the-candidates-say-analyzing-republican-debates-using-r) where he demonstrated some scraping and analysis techniques.  Here I highlight a combination usage of **textshape** tools to scrape and structure the text from 4 of the 2015 Republican debates within a [**magrittr**](https://github.com/smbache/magrittr) pipeline.  The result is a single [**data.table**](https://github.com/Rdatatable/data.table) containing the dialogue from all 4 debates.  The code highlights the conciseness and readability of **textshape** by restructuring Flores scraping with **textshape** replacements.

```{r}
if (!require("pacman")) install.packages("pacman")
pacman::p_load(rvest, magrittr, xml2)

debates <- c(
    wisconsin = "110908",
    boulder = "110906",
    california = "110756",
    ohio = "110489"
)

lapply(debates, function(x){
    xml2::read_html(paste0("http://www.presidency.ucsb.edu/ws/index.php?pid=", x)) %>%
        rvest::html_nodes("p") %>%
        rvest::html_text() %>%
        textshape::split_index(., grep("^[A-Z]+:", .)) %>%
        #textshape::split_match("^[A-Z]+:", TRUE, TRUE) %>% #equal to line above
        textshape::combine() %>%
        textshape::split_transcript() %>%
        textshape::split_sentence()
}) %>%
    textshape::bind_list("location")
```



